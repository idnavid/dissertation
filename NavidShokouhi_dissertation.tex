\documentclass[doublespacing]{utdthesis}
% For one-and-a-half spacing, use: \documentclass[halfspacing]{utdthesis}

%%% Load any desired packages in the space below.
%%% Warning: Do not load packages that change the margins, headers, or footers!
%%%
% Optional: If you want to use Times as your font, load it here.  Note that
% although package "times" should work, it may not be the best choice.  Newer
% LaTeX distributions offer "mathptmx" and "newtxtext,newtxmath" as superior
% replacements.  You should find out which is best for your LaTeX.  (If this
% sounds confusing, you probably shouldn't try to change the font to Times.)
%\usepackage{times}
%
% Optional: If your LaTeX has microtype, use it to improve text quality:
\usepackage{microtype}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{url}
\usepackage{tipa}
\usepackage{multirow}
\usepackage[authoryear]{natbib}
\usepackage[table,xcdraw]{xcolor}
\usepackage[labelsep=period]{caption}
\usepackage{listings}
\usepackage{color}
\usepackage{acronym}
\usepackage{rotating}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
	language=Java,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numbers=none,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3
}
\bibliographystyle{chicago}
\setlength{\bibsep}{12pt plus 1pt minus 1pt}
\let\cite=\citep

\usepackage{ifpdf}
\ifpdf
  \usepackage{hyperref}
\fi
%
%%% End of packages.

%%% Define all your personal macros here (if you have any).
%
\providecommand{\hyperref}[2][]{#2}

\newenvironment{exampleclasscode}
 {\parindent=1cm\vskip0pt plus2pt minus0pt\begin{verse}}
 {\end{verse}\vskip0pt plus2pt minus0pt}


%
%%% End of personal macro definitions.


%%% The following definitions MUST come before the document begins.
%
\author{Navid Shokouhi}
\title{Automatic Speaker Recognition and Diarization \\
	in Co-channel Speech}
\thesistype{Dissertation}  % or "Thesis"
\degreefull{Doctor of Philosophy}
\degreeabbr{PhD}
\subject{Electrical Engineering}
\graduationmonth{May}
\graduationyear{2017}
\prevdegrees{BS} % comma-separated list of PREVIOUS degrees

% List committee members in order.  Mark chairpersons with a "*":
\committeemember*{John H. L. Hansen}
\committeemember{Carlos Busso}
\committeemember{Issa M. S. Panahi}
\committeemember{P. K. Rajasekaran}
%
%%% End of definitions.

%%
% Acronyms 
\newcommand{\abbrlabel}[1]{\makebox[3cm][l]{#1\ \dotfill}}
\newenvironment{abbreviations}{\begin{list}{}{\renewcommand{\makelabel}{\abbrlabel}}}{\end{list}}
%%
%%% Beginning of actual thesis document.

\begin{document}

\frontmatter

\signaturepage
\copyrightpage{2017} % optional

\begin{dedication} % optional
Dedicated to my parents, Hossein and Manzar, \\ 
and my brother, Ali \\
\end{dedication}

\maketitle

\begin{acks}{November 2016} % date when thesis first submitted to committee
	This study would not have been possible without the support of my advisor, Professor John H. L. Hansen. 
	For years he has managed the Center for Robust Speech Systems (CRSS), where several students and research staff have benefited from his professional and scientific support. 
	I would also like to acknowledge all the students and staff at CRSS whose presence was an encouragement for remaining productive during the course of this study. 
	
	I thank Dr. Carlos Busso, Dr. Issa Panahi, and Dr. P. K. Rajasekaran for agreeing to sit as committee members and assess my work. 
	I would especially like to thank Dr. Rajasekaran, who in addition to being a committee member, provided constant advice and encouragement during my years as a PhD student. 
	
	At last I thank my parents, Hossein Shokouhi and Manzar Mohammadi. 
	My father, Hossein, functioned as a second PhD advisor for me from across the globe by sharing his own experience as a PhD student and encouraging me throughout my work. 
	
	This project was funded by AFRL and partially by The University of Texas at Dallas from the Distinguished University Chair in Telecommunications Engineering held by Professor John H. L. Hansen.

\end{acks}

\begin{abstract}
This study investigates various aspects of multi-speaker interference and its impact on speaker recognition. 
Single-channel multi-speaker speech signals (aka co-channel speech) comprise a significant portion of speech processing data. 
Examples of co-channel signals are recordings from multiple speakers in meetings, conversations, debates, etc. 
The nuisances of co-channel speech are two-fold: 1) overlapped speech, and 2) non-overlapping speaker interference. 
In overlap, the direct effects of two stochastically similar, non-stationary signals added together disrupts speech processing performance, originally developed for single-speaker audio. 
For example, in speaker recognition, identifying speakers in overlapped segments is more difficult compared to single-speaker signals. 
Analyses in this study show that introducing overlapped speech increases speaker recognition error rates by an order of magnitude. 
In addition to the direct impact of overlap, its secondary effect is in how one speaker forces the other to change his/her speech characteristics. 
Different forms of co-channel data are investigated in this study. 
In scenarios where the focus is on overlap, independent cross-talk is used. 
Independent cross-talk refers to the summation of independent audio signals from different speakers to simulate overlap. 
The alternative form of data used in this study is real conversation recordings. 
Although conversations contain both overlapped and non-overlapped speech, independent cross-talk is a better source of overlap. 
The reason real conversations are not deemed sufficient for overlap analysis is the scarcity and non-uniformity of overlaps in typical conversations. 
Independent cross-talk is obtained from the GRID corpus, which was used in the speech separation challenge as a source of overlapped speech. 
Real conversations are obtained from the Switchboard telephone conversation corpus. 
Other real conversational data used throughout this study include: the AMI meeting corpus, Prof-life-log, and UTDrive data. 
These datasets provide a perspective towards environment noise and co-channel interference in day-to-day speech. 
Categorizing datasets allows for a meticulous analysis of different aspects of co-channel speech. 
Most of the focus in analyzing overlaps is presented in the form of overlap detection techniques. 
This study proposes two overlap detection methods: 1) Pyknogram-based 2) Gammatone sub-band frequency modulation (GSFM). 
Both methods take advantage of the harmonic structure of speech to detect overlaps. 
Pyknograms do so by enhancing speech harmonics and evaluating dynamics across time, while GSFM magnifies the presence of multiple harmonics in different sub-bands. 
The other advancements proposed in this study use back-end modeling techniques to compensate for co-channel speech in real conversational data. 
These techniques are presented to reduce the impact of interfering speech in speaker-dependent models. 
Several methods are investigated, all of which propose a different modification to the popular probabilistic linear discriminant analysis (PLDA) used in state-of-the-art speaker recognition systems. 
In addition to model compensation techniques, this study presents CRSS-SpkrDiar, which is a speaker diarization research platform aimed at tackling conversational co-channel speech data. 
CRSS-SpkrDiar was developed during this study to alleviate end-to-end co-channel speech analysis. 
Taken collectively, the speech analysis, proposed features, and algorithmic advancements developed in this study all contribute to an improved understanding and measurable performance gain in speech/speaker technology for the co-channel speech problem. 

\end{abstract}

\tableofcontents
\listoffigures % required if you have any figures
\listoftables % required if you have any tables


\mainmatter


\include{chapters/introduction}

\include{chapters/frontend_sp}

\include{chapters/ovl_in_sid}

\include{chapters/backend_modeling}

\include{chapters/speaker_diarization}

\include{chapters/applications}

\include{chapters/conclusions}

\include{chapters/appendix}





\begin{thesisbib}
	\bibliography{refs.bib}
\end{thesisbib}  % <-- THIS LINE IS REQUIRED!

\begin{biosketch}
	Navid Shokouhi was born in Ahvaz, Khuzestan, Iran on June 9, 1989, to Hossein Shokouhi and Manzar Mohammadi. 
	His parents decided to move to Australia soon after he was born.
	%He was raised bilingual, speaking Farsi at home with his parents and English at school and with his friends. 
	At the age of 9 he and his parents moved back to Ahvaz, where his father was hired as an Assistant Professor of Linguistics in Shahid Chamran University. 
	Navid attended Amirkabir University of Technology (AUT) in Tehran as a Bachelors student in Electrical Engineering in 2007. 
	He graduated with a Degree in Electrical Engineering in 2011. 
	As a senior undergraduate student he worked with Dr. Hamid Sheikhzadeh for his final project. 
	There he was introduced to basic principles of speech signal processing. 
	His undergraduate senior project at AUT was on voice conversation and speech synthesis. 
	In the Fall of 2011 he moved to the United States to pursue a PhD degree under the supervision of Professor John H. L. Hansen at The University of Texas at Dallas (UTD). 
	In the Center for Robust Speech Systems (CRSS) at UTD he primarily focused on speaker recognition, specifically in multi-speaker environments. 
	He participated in a number of NIST Speaker Recognition Evaluations during his time as a PhD student at CRSS. 
	In 2013 he was awarded the IBM best student paper award by the IEEE signal processing society alongside three other student co-authors for a paper in ICASSP 2013 on the CRSS system for speaker recognition in the 2012 NIST SRE challenge. 
	In the Summer of 2015 he was recruited as an intern at ToyTalk Inc., where he developed speech processing tools for mobile platforms. 
	He is expected to graduate with a PhD degree in Electrical Engineering -- Signal Processing from The University of Texas at Dallas in 2016. 
\end{biosketch}



\begin{vita}
\newenvironment{list1}{
	\begin{list}{\ding{113}}{%
			\setlength{\itemsep}{0in}
			\setlength{\parsep}{0in} \setlength{\parskip}{0in}
			\setlength{\topsep}{0in} \setlength{\partopsep}{0in} 
			\setlength{\leftmargin}{0.17in}}}{\end{list}}
\newenvironment{list2}{
	\begin{list}{$\bullet$}{%
			\setlength{\itemsep}{0in}
			\setlength{\parsep}{0in} \setlength{\parskip}{0in}
			\setlength{\topsep}{0in} \setlength{\partopsep}{0in} 
			\setlength{\leftmargin}{0.2in}}}{\end{list}}


\textbf{\sc \bf Navid Shokouhi\\\\}
\begin{tabular}{@{}p{2.25in}p{4in}}
	%Department of Electrical Engineering & \\            
	%ECSN 4.416 & \\%{\it Fax:}    (412) 268-7828 \\         
	%The University of Texas at Dallas &  {\it Phone:}  (469) 394-6868\\
	%800 W. Campbell Rd. &  {\it E-mail:}  navid.shokouhi@utdallas.edu\\     
	%Richardson, TX 75080, USA &  {\it web:} www.linkedin.com/in/navidshokouhi\\       
	424 Dorset Rd., &    {\it Phone:} +1 (469) 394-6868\\        
	Croydon, &  {\it E-mail:}  navid.shokouhi@utdallas.edu\\     
	Melbourne, VIC 3136  &  {\it web:} www.linkedin.com/in/navidshokouhi\\         
	Australia &  
	
\end{tabular}

\line(1,0){435}


\vspace{0mm}
\textbf{\sc Research Interests\\\\}
Robust speech/speaker recognition, \\
Acoustic Modeling, Machine learning

\line(1,0){435}

\textbf{\sc Education\\\\}
{\bf The University of Texas at Dallas}, \\
%{\em Department of Statistics} 
\vspace*{-.1in}
\begin{list1}
	\item[] Ph.D. Candidate, EE, Fall 2011 - present \\
	Expected graduation date: December 2016
	\begin{list2}
		\vspace*{0.in}
		\item[-]Dissertation Topic:  ``Speaker Recognition and Diarization in Co-channel Speech'' \\
		{\it Addresses tangible solutions for speaker recognition \\in multi-speaker speech signals (e.g. meetings, conversations, etc.) }
		\item[-]Advisor:  Dr. John H. L. Hansen
	\end{list2}
\end{list1}
\vspace{3mm}
{\bf Amirkabir University of Technology}, Tehran, Iran\\
%{\em Department of Mathematics and Statistics} 
\vspace*{-.1in}
\begin{list1}
	\item[] B.Eng., Electrical Engineering
\end{list1}
\vspace{0mm}
\line(1,0){435}


\textbf{\sc Experience\\\\}
{\bf Intern} \hfill {June 2015 - Aug 2015}\\
ToyTalk Inc.
\begin{list1}
	\item[] {\it Speech engineering intern \\Built online/offline voice activity detection
		.}
	\vspace{2mm}
\end{list1}



{\bf Research Assistant} \hfill {September 2011 - Present}\\
The University of Texas at Dallas

%\vspace{-1mm}
%{\bf Undergraduate Research} \hfill {June 2010 - August 2011}\\
%Amirkabir University of Technology, Tehran, Iran
%
%\vspace{-1mm}
%{\bf Electronics Lab Instructor} \hfill {September 2010 - December 2010}\\
%Amirkabir University of Technology, Tehran, Iran
%\begin{list1}
%\item[] {\it Responsibilities included teaching, evaluation,\\ and grading junior undergraduates.}
%\end{list1}
\vspace{0mm}
\line(1,0){435}
%\vspace{-3mm}


\vspace{0mm}
\textbf{\sc Honors and Awards\\\\} 
{\bf ICASSP 2013 best student paper award} \hfill {February 2013}\\
IEEE Signal Processing Society on behalf of IBM

\vspace{2mm}
{\bf Undergraduate Honors student}\hfill {2011}\\
Amirkabir University of Technology, Tehran, Iran \\
Exemption from graduate school entrance exam

\vspace{0mm}

\vspace{0mm}
\line(1,0){435}
\vspace{0mm}

\textbf{\sc Projects\\\\}
{\bf 2012 NIST Speaker Recognition Evaluation} \hfill {June 2012 - October 2012}\\
{\it Managed the fusion/calibration system for the \\UTDallas SRE submission.}\\

\vspace{-1mm}
{\bf 2014 NIST i-vector challenge} \hfill { December 2013}\\

%\vspace{-5mm}
{\bf 2016 NIST Speaker Recognition Evaluation} \hfill { October 2016}\\

{\bf CRSS-SpkrDiar} \hfill { 2016}\\
{\it Developed C++ library for end-to-end speaker diarization.}\\
\line(1,0){435}

\textbf{\sc Skills\\} 
\begin{list2}
	\item Python, C++, MATLAB: use on a daily basis.
	\item Perl and Bash scripting: basic familiarity for text processing.
\end{list2}
\vspace{0mm}
\line(1,0){435}

\textbf{\sc Test Scores\\\\}
{\bf Iranian Regional Olympiads for University Students - Electrical Eng.} \hfill {March 2010}\\
Tehran, Iran
\begin{list1}
	\item[] {\it Ranked 8th}
\end{list1}
\vspace{-0mm}
{\bf Iranian National Olympiads for University Students - Electrical Eng.} \hfill {June 2010}\\
Tehran, Iran
\begin{list1}
	\vspace{-0mm}
	\item[] {\it Ranked 20th}
\end{list1}
\line(1,0){435}
\vspace{0mm}

\textbf{\sc Volunteer Work\\\\}
\vspace{0mm}
{\bf IEEE SLT Committee Newsletter} \hfill {January 2013 - 2016}\\
News staff reporter\\

{\bf SLT 2014 organizing committee - lead student volunteer} \hfill {December 2014}\\
\vspace{0mm}
\line(1,0){435}

\textbf{\sc Publications\\}

{\bf Navid Shokouhi}, John H. L. Hansen, ``Teager-Kaiser Energy Operators for Overlapped Speech Detection, '' submitted to IEEE Trans. on ASLP (accepted -- to be published in 2017). \\

{\bf Navid Shokouhi}, John H. L. Hansen, ``Speaker Recognition in Co-channel Speech Using Modified Probabilistic Linear Discriminant Analysis, '' JP -- (under revision).\\

John H. L. Hansen, Mahesh Kumar Nandwana, {\bf Navid Shokouhi}, ``Analysis of human scream
and its impact on text-independent speaker verication, '' submitted to JASA (under revision).\\

Yang Zheng, {\bf Navid Shokouhi}, Nicolai Thomsen, Amardeep Sathyanarayana, John H. L. Hansen, ``Towards Developing a Distraction-Reduced Hands-Off Interactive Driving Experience using Portable Smart Devices, '' SAE Technical Paper, January 2016. \\

{\bf Navid Shokouhi}, Yang Zheng, Amardeep Sathyanarayana, John H. L. Hansen, ``In-Vehicle Conversation Analysis towards Improved Driver Assistance Systems,'' 7th Biennial Workshop on DSP for In-Vehicle Systems and Safety, Berkeley, CA, October 2015.\\

{\bf Navid Shokouhi}, John H. L. Hansen, ``Probabilistic Linear Discriminant Analysis for Robust Speaker Identification in Co-channel Speech,'' 16th Annual Conference of the International Speech Communication Association (INTERSPEECH), Dresden, Germany, Sept. 6-10, 2015.\\

{\bf Navid Shokouhi}, Ali Ziaei, Abhijeet Sangwan, John H. L. Hansen, ``Robust Overlapped Speech Detection and its Applications in Word-Count Estimation for Prof-Life-Log Data,'' IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brisbane, Australia, April 2015. \\

{\bf Navid Shokouhi}, Seyed Omid Sadjadi, John H. L. Hansen, ``Co-channel Speech Detection via Spectral Analysis of Frequency Modulated Sub-bands,'' 15th Annual Conference of the International Speech Communication Association (INTERSPEECH), Singapore, September 2014.\\

Gang Liu, Chengzhu Yu, Abhinav Misra, {\bf Navid Shokouhi}, John H. L. Hansen , ``Investigating State-of-the-Art Speaker Verification in the Case of Unlabeled Development Data,'' Odyssey: The Speaker and Language Recognition Workshop, Finland, 2014.\\

Jamal Amini, Abdoreza Sabzi Shahrebabaki, {\bf Navid Shokouhi}, Hamid Sheikhzadeh, Kamran Raahemifar, Mahdi Eslami,  ``Speech analysis/synthesis by Gaussian mixture approximation of the speech spectrum for voice conversion'' IEEE International Symposium on Signal Processing and Information Technology (ISSPIT), Greece, December 2013.\\

Amardeep Sathyanarayana, {\bf Navid Shokouhi}, Seyed Omid Sadjadi, John H. L. Hansen, ``Belt Up: Investigating the impact of in-vehicular conversation on driving performance,'' Intelligent Vehicles Symposium (IV), IEEE, Australia, June 2013. \\

Taufiq Hasan, Seyed Omid Sadjadi, Gang Liu, {\bf Navid Shokouhi}, Hynek Boril, John H. L. Hansen, ``CRSS systems for 2012 NIST speaker recognition evaluation,'' IEEE International Conference on Acoustics, Speech and Signal Processing, Vancouver, BC, May 2013. \\

{\bf Navid Shokouhi}, Amardeep Sathyanarayana, Seyed Omid Sadjadi, John H. L. Hansen, ``Overlapped-speech detection with applications to driver assessment for in-vehicle active safety systems,'' IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Vancouver, BC, May 2013. \\

{\bf Navid Shokouhi}, Amardeep Sathyanarayana, Seyed Omid Sadjadi, John H. L. Hansen, ``Analysis of In-Vehicle Speech Activity towards Driver Safety Assessment,'' 6th Biennial Workshop on DSP for In-Vehicle Systems and Safety, Seoul, South Korea, 2013.\\

{\bf Navid Shokouhi} among others, ``I4U submission to NIST SRE 2012: A large-scale collaborative effort for noise-robust speaker verification,'' 14th Annual Conference of the International Speech Communication Association (INTERSPEECH), Lyon, France, August 2013.\\\\

\textbf{\sc Online Articles}
John H. L. Hansen, {\bf Navid Shokouhi}, ``Speaker Identification: Screaming, Stress and Non-Neutral Speech, is there speaker content?'' IEEE Speech and Language Technical Committee (SLTC) Newsletter, November 2013.\\

Taufiq Hasan, Gang Liu, Seyed Omid Sadjadi, {\bf Navid Shokouhi}, H BoÅ™il, A Ziaei, Abhinav Misra, KW Godin, John H. L. Hansen, ``UTD-CRSS systems for 2012 NIST speaker recognition evaluation,'' Proc. NIST SRE Workshop, December 2012. \\

Chunlei Zhang, Fahimeh Bahmaninezhad, Shivesh Ranjan, Chengzhu Yu, {\bf Navid Shokouhi}, John H. L. Hansen. ``UTD-CRSS Systems for 2016 NIST Speaker Recognition Evaluation, '' arXiv preprint arXiv:1610.07651, October 2016. 


\end{vita}
\end{document}
