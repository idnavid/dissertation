\documentclass[doublespacing]{utdthesis}
% For one-and-a-half spacing, use: \documentclass[halfspacing]{utdthesis}

%%% Load any desired packages in the space below.
%%% Warning: Do not load packages that change the margins, headers, or footers!
%%%
% Optional: If you want to use Times as your font, load it here.  Note that
% although package "times" should work, it may not be the best choice.  Newer
% LaTeX distributions offer "mathptmx" and "newtxtext,newtxmath" as superior
% replacements.  You should find out which is best for your LaTeX.  (If this
% sounds confusing, you probably shouldn't use Times at all.)
%\usepackage{times}
%
% Optional: If your LaTeX has microtype, use it to improve text quality:
\usepackage{microtype}
%
% Recommended: If your thesis contains math, use the AMS packages:
\usepackage{amsmath,amssymb,amsthm}
%
% Recommended: If your thesis needs to import graphics, use graphicx:
\usepackage{graphicx}
%
% Recommended: If your bibliography contains web page URLs, the url package
% improves their appearance (e.g., better line breaking):
\usepackage{url}
\usepackage{tipa}
%
\usepackage{multirow}
% Required: To satisfy UTD's formatting requirements for citations, use the
% "natbib" package.  (Use other citation packages at your own risk; not all
% are flexible enough to meet UTD's requirements.)  If you wish to use numeric
% citations, change "authoryear" to "numbers" below.  Use the "chicago" BibTeX
% style, which most closely matches the Turabian formatting required by UTD.
% UTD mandates a blank line between each pair of bibliography entries, so set
% \bibsep as shown below.  Finally, if you are accustomed to using \cite as
% your citation macro, point it to natbib's \citep macro as shown.
\usepackage[authoryear]{natbib}
\usepackage[table,xcdraw]{xcolor}
\usepackage[font={small}]{caption}
\usepackage{listings}
\usepackage{color}
\usepackage{acronym}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
	language=Java,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numbers=none,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3
}



\bibliographystyle{chicago}
\setlength{\bibsep}{12pt plus 1pt minus 1pt}
\let\cite=\citep
%
% Required: If you have any wide tables or figures that need to be typeset
% in landscape, use the rotating package:
\usepackage{rotating}
%
% Optional: If you use hyperref to auto-generate hyperlinks, always load it
% LAST since it modifies everything else.  In addition, only load hyperref if
% you use pdftex or pdflatex to generate PDFs directly.  Do NOT use it if you
% use plain tex or latex to generate a DVI file.  (If you are generating DVI
% files which you then convert to PDF, you should seriously consider switching
% to pdflatex.  The DVI format loses information because it cannot support
% modern PDF document features.  Using pdflatex to generate PDFs directly
% therefore results in PDFs of significantly higher quality.)
\usepackage{ifpdf}
\ifpdf
  \usepackage{hyperref}
\fi
%
%%% End of packages.

%%% Define all your personal macros here (if you have any).
%
\providecommand{\hyperref}[2][]{#2}

\newenvironment{exampleclasscode}
 {\parindent=1cm\begin{verse}}
 {\end{verse}}
%
%%% End of personal macro definitions.


%%% The following definitions MUST come before the document begins.
%
\author{Navid Shokouhi}
\title{Automatic Speaker Recognition and Diarization \\
		in Co-channel Speech}
\thesistype{Dissertation}  % or "Thesis"
\degreefull{Doctor of Philosophy}
\degreeabbr{PhD}
\subject{Electrical Engineering}
\graduationmonth{November}
\graduationyear{2016}
\prevdegrees{BS} % comma-separated list of PREVIOUS degrees

% List committee members in order.  Mark chairpersons with a "*":
\committeemember*{John H. L. Hansen}
\committeemember{Carlos Busso}
\committeemember{Issa Panahi}
\committeemember{P. K. Rajasakeran}
%
%%% End of definitions.


%%% Beginning of actual thesis document.

\newcommand{\abbrlabel}[1]{\makebox[3cm][l]{\textbf{#1}\ \dotfill}}
\newenvironment{abbreviations}{\begin{list}{}{\renewcommand{\makelabel}{\abbrlabel}}}{\end{list}}

\begin{document}

\frontmatter

\signaturepage
%\copyrightpage{2012} % optional

\begin{dedication} % optional
Dedicated to my parents, Hossein and Manzar, \\ 
and my brother, Ali \\
\end{dedication}

\maketitle

\begin{acks}{November 2016} % date when thesis first submitted to committee
This study would not have been possible without the support of my advisor, Prof. John H. L. Hansen. 
For years he has managed the Center for Robust Speech System (CRSS), where several students and research staff have benefited from his professional and scientific support. 
I would also like to acknowledge all the students and staff at CRSS whose presence was an encouragement for remaining productive during the course of this study. 

I thank Dr. Carlos Busso, Dr. Issa Panahi, and Dr. P. K. Rajasekaran for agreeing to sit as committee members and assess my work. 
I would especially like to thank Dr. Rajasekaran, who in addition to being a committee member, provided constant advice and encouragement during my years as a PhD student. 

At last I thank my parents Hossein Shokouhi and Manzar Mohammadi. 
My father, Hossein, functioned as a second PhD advisor for me from across the globe by sharing his own experience as a PhD student and encouraging me throughout my work. 

This project was funded by AFRL and partially by the University of Texas at Dallas from the Distinguished University Chair in Telecommunications Engineering held by Prof. John H.L. Hansen.

\end{acks}

%\begin{preface} % may or may not be required, depending on thesis content
%% author may insert additional preface text here
%%\prefacetext
%% author may insert additional preface text here
%\end{preface}

\begin{abstract}
%500 words
This study investigates various aspects of multi-speaker interference and its impact on speaker recognition. 
Single-channel multi-speaker speech signals (aka co-channel speech) comprise a significant portion of speech processing data. 
Examples of co-channel signals are recordings from multiple speakers in meetings, conversations, debates, etc. 
The nuisances of co-channel speech are two-fold: 1) overlapped speech, and 2) non-overlapping speaker interference. 
In overlap, the direct effects of two stochastically similar, non-stationary signals added together disrupts speech processing performance, originally developed for single-speaker audio. 
For example, in speaker recognition, identifying speakers in overlapped segments is more difficult compared to single-speaker signals. 
Analyses in this study show that introducing overlapped speech increases speaker recognition error rates by an order of magnitude. 
In addition to the direct impact of overlap, its secondary effect is in how one speaker forces the other to change his/her speech characteristics. 

Different forms of co-channel data are investigated in this study. 
In scenarios where the focus is on overlap, independent cross-talk is used. 
Independent cross-talk refers to the summation of independent audio signals from different speakers to simulate overlap. 
The alternative form of data used in this study is real conversation recordings. 
Although conversations contain both overlapped and non-overlapped speech, independent cross-talk is a better source of overlap. 
The reason real conversations are not deemed sufficient for overlap analysis is the scarcity and non-uniformity of overlaps in typical conversations. 
Independent cross-talk is obtained from the GRID corpus, which was used in the speech separation challenge as a source of overlapped speech. 
Real conversations are obtained from the Switchboard telephone conversation corpus. 
Other real conversational data used throughout this study include: the AMI meeting corpus, Prof-life-log, and UTDrive data. 
These datasets provide a perspective towards environment noise and co-channel interference in day-to-day speech. 

Categorizing datasets allows for a meticulous analysis of different aspects of co-channel speech. 
Most of the focus in analyzing overlaps is presented in the form of overlap detection techniques. 
This study proposes two overlap detection methods: 1) Pyknogram-based 2) Gammatone sub-band frequency modulation (GSFM). 
Both methods take advantage of the harmonic structure of speech to detect overlaps. 
Pyknograms do so by enhancing speech harmonics and evaluating dynamics across time, while GSFM magnifies the presence of multiple harmonics in different sub-bands. 
The other advancements proposed in this study use back-end modeling techniques to compensate for co-channel speech in real conversational data. 
These techniques are presented to reduce the impact of interfering speech in speaker-dependent models. 
Several methods are investigated, all of which propose a different modification to the popular probabilistic linear discriminant analysis (PLDA) used in state-of-the-art speaker recognition systems. 
In addition to model compensation techniques, this study presents CRSS-SpkrDiar, which is a speaker diarization research platform aimed at tackling conversational co-channel speech data. 
CRSS-SpkrDiar was developed during this study to alleviate end-to-end co-channel speech analysis. 

Taken collectively, the speech analysis, proposed features, and algorithmic advancements developed in this study all contribute to an improved understanding and measurable performance gain in speech/speaker technology for the co-channel speech problem. 


\end{abstract}

\tableofcontents
\listoffigures % required if you have any figures
\listoftables % required if you have any tables

\newpage
LIST OF ACRONYMS
\begin{abbreviations}
	\item[API] Application Programming Interface
	\item[ASR] Automatic Speech Recognition
	\item[BIC] Bayesian Information Criterion
	\item[DCF] Detection Cost Function
	\item[DER] Diarization Error Rate
	\item[DESA] Discrete Energy Separation Algorithm
	\item[EER] Equal Error Rate
	\item[EM] Expectation Maximization
	\item[ERB] Equivalent Rectangular Bandwidth
	\item[FA] False Alarm
	\item[FM] Frequency Modulation
	\item[GLPK] GNU Linear Programming Kit
	\item[GMM] Gaussian Mixture Model
	\item[GSFM] Gammatone Sub-band Frequency Modulation
	\item[HMM] Hidden Markov Model
	\item[ILP] Integer Linear Programming
	\item[LDA] Linear Discriminant Analysis
	\item[MFCC] Mel Frequency Cepstral Coefficients
	\item[NIST] National Institute of Standards and Technology
	\item[OVL] Overlap
	\item[PLDA] Probabilistic Linear Discriminant Analysis
	\item[SAD] Speech Activity Detection
	\item[SAPVR] Spectral Autocorrelation Peak-Valley Ratio
	\item[SFM] Spectral Flatness Measure
	\item[SIR] Signal-to-Interference Ratio
	\item[SNR] Signal-to-Noise Ratio
	\item[SRE] Speaker Recognition Evaluation
	\item[SSC] Speech Separation Challenge
	\item[SVM] Support Vector Machine
	\item[TEO] Teager Energy Operator
	\item[TV] Total Variability
	\item[UBM] Universal Background Model
	\item[WCE] Word-Count Estimation
\end{abbreviations}


\mainmatter

\include{chapters/introduction}

\include{chapters/frontend_sp}

\include{chapters/ovl_in_sid}

\include{chapters/backend_modeling}

\include{chapters/speaker_diarization}

\include{chapters/applications}

\include{chapters/conclusions}

\include{chapters/appendix}

\begin{thesisbib}
\bibliography{refs.bib}
\end{thesisbib}  % <-- THIS LINE IS REQUIRED!

\begin{vita}
Navid Shokouhi was born in Ahvaz, Khuzestan, Iran on June 9, 1989, to Hossein Shokouhi and Manzar Mohammadi. 
His parents decided to move to Australia soon after he was born.
%He was raised bilingual, speaking Farsi at home with his parents and English at school and with his friends. 
At the age of 9 he and his parents moved back to Ahvaz, where his father was hired as an Assistant Professor of Linguistics in Shahid Chamran University. 
Navid attended Amirkabir University of Technology (AUT) in Tehran as a Bachelors student in Electrical Engineering in 2007. 
He graduated with a Degree in Electrical Engineering in 2011. 
As a senior undergraduate student he worked with Dr. Hamid Sheikhzadeh for his final project. 
There he was introduced to basic principles of speech signal processing. 
His undergraduate senior project at AUT was on voice conversation and speech synthesis. 
In the Fall of 2011 he moved to the United States to pursue a PhD degree under the supervision of Prof. John H. L. Hansen at the University of Texas at Dallas (UTD). 
In the Center for Robust Speech Systems (CRSS) at UTD he primarily focused on speaker recognition, specifically in multi-speaker environments. 
He participated in a number of NIST Speaker Recognition Evaluations during his time as a PhD student at CRSS. 
In 2013 he was awarded the IBM best student paper award by the IEEE signal processing society alongside three other student co-authors for a paper in ICASSP 2013 on the CRSS system for speaker recognition in the 2012 NIST SRE challenge. 
In the Summer of 2015 he was recruited as an intern at ToyTalk Inc., where he developed speech processing tools for mobile platforms. 
He is expected to graduate with a PhD degree in Electrical Engineering -- Signal Processing from the University of Texas at Dallas in 2016. 
\end{vita}

\end{document}

