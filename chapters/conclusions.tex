\chapter{CONCLUSIONS}

This study presented a detailed description of co-channel speech analysis in the context of speaker recognition. 
As repeatedly mentioned throughout the course of this thesis, co-channel speech refers to single-channel audio signals with more than one speaker. 
Great care was taken to highlight the difference between overlap and co-channel speech. 
While co-channel refers to any signal with more than one speaker, overlap refers to parts of co-channel audio where more than one speaker is speaking. 
The distinction between overlap and co-channel is the first contribution of this thesis. 
Although this contribution may appear trivial at first glance, it was shown that the majority of co-channel research considers overlap synonymous to co-channel speech, a misconception that reduces the applicability of some attempts to compensate overlapped speech in speaker recognition. 
In other words, addressing overlap in co-channel speech is not sufficient for a large class of speaker recognition problems. 
This narrative is carried out throughout the first few investigations of this study. 

The study considers the impact of overlapped speech on speaker recognition performance. 
Speaker recognition is typically manifested through speaker verification experiments. 
It was shown that replacing single-speaker audio data with overlapped data reduces verification performance to up to one order of magnitude. 
For example, equal error rates increase from 1.5\% for single-speaker audio from the GRID corpus to approximately 23\% for overlapped data (depending on the nominal signal-to-interference ratio). 
This observation shows the legitimacy of past studies in prioritizing overlap relative to other forms of co-channel data. 
The traditional approach to deal with such drastic performance drop is to measure/detect overlapped segments in speaker recognition experiments. 
Therefore, the second stage of this study provides an extensive investigation of overlap detection methods. 

Overlap detection provides a unique perspective in highlighting the differences between single-speaker and overlapped speech. 
The algorithms proposed in this study focus on the harmonic structure of speech. 
Speech harmonics have traditionally been used as a way to identify overlapped speech. 
The fact that speaker recognition is highly influenced by voiced speech further motivates this approach. 
Harmonics are an important component of voiced speech and therefore, harmonic based analyses of overlapped speech fits well with the theme of this study. 
The two methods proposed for overlap detection are: 1) Pyknograms and 2) Gammatone sub-band frequency modulation (GSFM). 
Pyknogram extraction is a 2 step process of obtaining a binary mask for time-frequency units corresponding to the amplitude spectrogram. 
Frequencies across the spectrogram are first estimated using the Teager Energy Operator (step 1). 
The estimated frequencies are then pruned to only include prominent resonances (step 2). 
Pyknograms provide two important features that are useful for overlap detection: 1) unlike many existing speech representations, Pyknograms do not depend on the number of speakers; 2) Pyknograms are effective in suppressing non-harmonic speech, which provides robust performance in noisy conditions. 
In addition to Pyknograms, GSFM was also proposed as a way to magnify the presence of multiple harmonics in time-frequency units. 
GSFM incorporates the non-linearity of sinusoidal frequency modulation to obtain frequency modulation spectra. 
The relative roll-off of FM spectra is then used to summarize the information in each time-frequency unit. 
Evaluations show that although in controlled conditions GSFM outperforms Pyknograms for overlap detection, under noisy conditions Pyknograms are significantly more reliable. 

In addition to introducing overlap detection methods, a novel technique is proposed that uses overlap detection decisions as quality measures for speaker recognition experiments. 
Using overlap detection as quality measures (aka meta-data) is more desirable compared to the traditional approach, which is to detect and remove overlapped segments. 
The advantage of quality measures is in the fact that not all overlapped speech should be thrown away, especially with limited data. 
The algorithm used to fuse quality measures with speaker recognition decisions is called Q-stack, which concatenates multiple scores and summarizes the final speaker verification decision using support vector machine (SVM) certainties. 
Fusing overlap meta-data with speaker verification scores relatively reduces speaker verification error rates by approximately 20\%. 

The study also focused on evaluating speaker recognition performance in co-channel speech. 
It was shown that although overlap is damaging to speaker recognition performance, the impact of co-channel is much more significant. 
In the case of Switchboard2 telephone conversations, the impact due to non-overlapping co-channel speech is over 18\% absolute increase in EER (single-speaker performance is 5\%). 
Meanwhile, the increase in EER due to overlapped speech is slightly over 2\%. 
This puts the impact of overlap vs. co-channel speech in perspective for real conversational speech. 
In an effort to compensate co-channel in realistic speaker recognition probelms, a standard i-vector/PLDA system was evaluated. 
Many approaches were investigated to improve probabilistic linear discriminant analysis (PLDA) for co-channel speech. 
1) One method was to add co-channel data to PLDA training, called mixed PLDA. 
Mixed PLDA was presented to treat speaker interference in the same manner PLDA addresses channel mismatch.
2) A second method was dual-eigenvoice PLDA (dePLDA). dePLDA uses two identical eigenvoice matrices to model within- and between-speaker variability. The difference between dePLDA and standard PLDA is in replacing the eigen-channel matrix with a second eigen-voice. 
3) The study also introduced co-channel aware PLDA (caPLDA), which proposed alternative formulations to PLDA for speaker recognition in co-channel speech. 
These alternative formulations replace within-speaker variability with a linear combination of between- and within-speaker covariances. 
Different coefficients are investigated in the proposed linear combination framework. 
Results show that although some performance improvement is obtained by the proposed caPLDA. 
dePLDA on the other provides significant improvement over mixedPLDA and standard PLDA.  

A speaker diarization research platform is presented in this study, called CRSS-SpkrDiar. 
Speaker diarization addresses the problem of ``who spoke when?'', which is a relevant question for co-channel signals. 
Therefore, diarization is considered an important aspect of speaker recognition in co-channel speech. 
In a sense, most of this thesis considered speaker recognition over entire co-channel signals, while speaker diarization addresses speaker recognition within a co-channel signal. 
CRSS-SpkrDiar is a C++ library that includes the implementation of state-of-the-art speaker diarization techniques. 
This study presents the main components of CRSS-SpkrDiar while providing sufficient details related to speaker diarization in general. 
CRSS-SpkrDiar is considered a major contribution of this comprehensive study on co-channel speech and is presented as a stepping stone for future work. 




